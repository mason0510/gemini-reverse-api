# Gemini Reverse API æ–‡æ¡£

## ğŸ“Œ æœåŠ¡ä¿¡æ¯

- **åŸºç¡€URL**: `http://82.29.54.80:8100`
- **åŸŸå**: `http://google-api.aihang365.com:8100`
- **åè®®**: HTTP
- **ç‰ˆæœ¬**: v1.1
- **è®¤è¯**: æ— éœ€ API Keyï¼ˆåŸºäºæœåŠ¡ç«¯ Cookieï¼‰

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ€ç®€å•çš„è°ƒç”¨ï¼ˆæ¨èï¼‰

```bash
curl -X POST http://82.29.54.80:8100/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-2.5-flash",
    "messages": [{"role": "user", "content": "ä½ å¥½"}]
  }'
```

---

## ğŸ“¡ API ç«¯ç‚¹

### 1. å¥åº·æ£€æŸ¥

æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚

**ç«¯ç‚¹**: `GET /health`

**è¯·æ±‚ç¤ºä¾‹**:
```bash
curl http://82.29.54.80:8100/health
```

**å“åº”**:
```json
{
  "status": "ok",
  "client_ready": true
}
```

> `client_ready` è¡¨ç¤ºCookieæ˜¯å¦å·²é…ç½®ä¸”å®¢æˆ·ç«¯å·²åˆå§‹åŒ–

---

### 2. Webé…ç½®ç•Œé¢

**ç«¯ç‚¹**: `GET /`

è¿”å›Webé…ç½®ç•Œé¢ï¼ˆHTMLé¡µé¢ï¼‰ï¼Œç”¨äºé…ç½®Cookieå’Œæµ‹è¯•APIã€‚

---

### 3. APIæœåŠ¡ä¿¡æ¯

è·å– API æœåŠ¡ä¿¡æ¯å’Œå¯ç”¨ç«¯ç‚¹ã€‚

**ç«¯ç‚¹**: `GET /api/info`

**è¯·æ±‚ç¤ºä¾‹**:
```bash
curl http://82.29.54.80:8100/api/info
```

**å“åº”**:
```json
{
  "service": "Gemini Reverse API",
  "version": "1.0",
  "endpoints": {
    "openai": "/v1/chat/completions",
    "gemini": "/gemini/v1beta/models/{model}:generateContent",
    "simple": "/v1/generate",
    "cookie_config": "/api/cookies"
  }
}
```

---

### 4. Cookieç®¡ç†

#### è·å–CookieçŠ¶æ€

**ç«¯ç‚¹**: `GET /api/cookies/status`

**å“åº”**:
```json
{
  "valid": true,
  "message": "Cookieæœ‰æ•ˆï¼Œå®¢æˆ·ç«¯å·²å°±ç»ª"
}
```

#### é…ç½®Cookie

**ç«¯ç‚¹**: `POST /api/cookies`

**è¯·æ±‚**:
```json
{
  "cookies": {
    "__Secure-1PSID": "xxx",
    "__Secure-1PSIDCC": "xxx",
    "__Secure-1PSIDTS": "xxx"
  }
}
```

**å“åº”**:
```json
{
  "success": true,
  "message": "Cookieä¿å­˜æˆåŠŸï¼Œå®¢æˆ·ç«¯å·²é‡æ–°åˆå§‹åŒ–"
}
```

---

### 5. è·å–æ¨¡å‹åˆ—è¡¨

**ç«¯ç‚¹**: `GET /api/models`

**å“åº”**:
```json
{
  "models": [
    {"id": "gemini-2.5-flash", "name": "å¿«é€Ÿ", "description": "å¿«é€Ÿå›ç­”ï¼Œé€‚åˆæ—¥å¸¸ä½¿ç”¨"},
    {"id": "gemini-2.5-pro", "name": "Pro", "description": "æ“…é•¿å¤„ç†é«˜é˜¶æ•°å­¦å’Œä»£ç é—®é¢˜"},
    {"id": "gemini-3.0-pro", "name": "Pro 3.0", "description": "æœ€æ–°Proæ¨¡å‹ï¼Œæ›´å¼ºçš„æ¨ç†èƒ½åŠ›"}
  ],
  "default": "gemini-2.5-flash"
}
```

---

## ğŸ”„ ä¸‰ç§è°ƒç”¨æ ¼å¼

### æ ¼å¼ 1: OpenAI å…¼å®¹æ ¼å¼ï¼ˆæ¨èï¼‰â­

é€‚åˆä» OpenAI API è¿ç§»çš„ç”¨æˆ·ï¼Œæ— éœ€ä¿®æ”¹ä»£ç ã€‚

**ç«¯ç‚¹**: `POST /v1/chat/completions`

**è¯·æ±‚å‚æ•°**:

| å‚æ•° | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `model` | string | å¦ | `gemini-2.5-flash` | æ¨¡å‹åç§° |
| `messages` | array | æ˜¯ | - | æ¶ˆæ¯æ•°ç»„ |
| `messages[].role` | string | æ˜¯ | - | è§’è‰²ï¼š`user` æˆ– `assistant` |
| `messages[].content` | string | æ˜¯ | - | æ¶ˆæ¯å†…å®¹ |

**è¯·æ±‚ç¤ºä¾‹**:
```bash
curl -X POST http://82.29.54.80:8100/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-2.5-flash",
    "messages": [
      {"role": "user", "content": "è§£é‡Šä¸€ä¸‹é‡å­è®¡ç®—"}
    ]
  }'
```

**å“åº”æ ¼å¼**:
```json
{
  "id": "chatcmpl-1734567890",
  "object": "chat.completion",
  "created": 1734567890,
  "model": "gemini-2.5-flash",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "é‡å­è®¡ç®—æ˜¯ä¸€ç§åˆ©ç”¨é‡å­åŠ›å­¦åŸç†..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 50,
    "total_tokens": 60
  }
}
```

**Python ç¤ºä¾‹**:
```python
import requests

response = requests.post(
    "http://82.29.54.80:8100/v1/chat/completions",
    json={
        "model": "gemini-2.5-flash",
        "messages": [
            {"role": "user", "content": "ä½ å¥½"}
        ]
    }
)

result = response.json()
print(result["choices"][0]["message"]["content"])
```

**Node.js ç¤ºä¾‹**:
```javascript
const axios = require('axios');

async function chat(message) {
  const response = await axios.post(
    'http://82.29.54.80:8100/v1/chat/completions',
    {
      model: 'gemini-2.5-flash',
      messages: [
        { role: 'user', content: message }
      ]
    }
  );

  return response.data.choices[0].message.content;
}

chat('ä½ å¥½').then(console.log);
```

---

### æ ¼å¼ 2: Gemini åŸç”Ÿæ ¼å¼

Google å®˜æ–¹ API å…¼å®¹æ ¼å¼ï¼Œæä¾›å®Œæ•´çš„ Token ç»Ÿè®¡ã€‚

**ç«¯ç‚¹**: `POST /gemini/v1beta/models/{model}:generateContent`

**è·¯å¾„å‚æ•°**:

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `model` | string | æ˜¯ | æ¨¡å‹åç§°ï¼Œå¦‚ `gemini-3-pro-preview` |

**è¯·æ±‚å‚æ•°**:

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `contents` | array | æ˜¯ | å†…å®¹æ•°ç»„ |
| `contents[].role` | string | æ˜¯ | è§’è‰²ï¼š`user` æˆ– `model` |
| `contents[].parts` | array | æ˜¯ | å†…å®¹éƒ¨åˆ†æ•°ç»„ |
| `contents[].parts[].text` | string | æ˜¯ | æ–‡æœ¬å†…å®¹ |
| `generationConfig` | object | å¦ | ç”Ÿæˆé…ç½®ï¼ˆå¯é€‰ï¼‰ |
| `generationConfig.temperature` | float | å¦ | æ¸©åº¦å‚æ•°ï¼ˆ0.0-1.0ï¼‰ |
| `generationConfig.maxOutputTokens` | int | å¦ | æœ€å¤§è¾“å‡º token æ•° |

**è¯·æ±‚ç¤ºä¾‹**:
```bash
curl -X POST http://82.29.54.80:8100/gemini/v1beta/models/gemini-3-pro-preview:generateContent \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [
      {
        "role": "user",
        "parts": [{"text": "è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ "}]
      }
    ],
    "generationConfig": {
      "temperature": 0.7,
      "maxOutputTokens": 1000
    }
  }'
```

**å“åº”æ ¼å¼**:
```json
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯..."
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "index": 0
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 8,
    "candidatesTokenCount": 245,
    "totalTokenCount": 253
  },
  "modelVersion": "gemini-3-pro-preview"
}
```

**Python ç¤ºä¾‹**:
```python
import requests

response = requests.post(
    "http://82.29.54.80:8100/gemini/v1beta/models/gemini-3-pro-preview:generateContent",
    json={
        "contents": [
            {
                "role": "user",
                "parts": [{"text": "ä½ å¥½"}]
            }
        ],
        "generationConfig": {
            "temperature": 0.7,
            "maxOutputTokens": 500
        }
    }
)

result = response.json()
text = result["candidates"][0]["content"]["parts"][0]["text"]
tokens = result["usageMetadata"]["totalTokenCount"]
print(f"å›å¤: {text}\nä½¿ç”¨ Token: {tokens}")
```

---

### æ ¼å¼ 3: ç®€åŒ–æ ¼å¼

æœ€ç®€å•çš„è°ƒç”¨æ–¹å¼ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•ã€‚

**ç«¯ç‚¹**: `POST /v1/generate`

**è¯·æ±‚å‚æ•°**:

| å‚æ•° | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `prompt` | string | æ˜¯ | - | æç¤ºè¯ |
| `model` | string | å¦ | `gemini-2.5-flash` | æ¨¡å‹åç§° |

**è¯·æ±‚ç¤ºä¾‹**:
```bash
curl -X POST http://82.29.54.80:8100/v1/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
    "model": "gemini-2.5-flash"
  }'
```

**å“åº”æ ¼å¼**:
```json
{
  "text": "æ˜¥é£æ‹‚é¢æš–äººå¿ƒï¼Œ\nä¸‡ç‰©å¤è‹å±•æ–°é¢œ...",
  "model": "gemini-2.5-flash"
}
```

**Python ç¤ºä¾‹**:
```python
import requests

response = requests.post(
    "http://82.29.54.80:8100/v1/generate",
    json={
        "prompt": "ä½ å¥½",
        "model": "gemini-2.5-flash"
    }
)

print(response.json()["text"])
```

---

## ğŸ–¼ï¸ å›¾ç‰‡ç”Ÿæˆæ¥å£

### æ ¼å¼ 1: OpenAI å…¼å®¹æ ¼å¼

**ç«¯ç‚¹**: `POST /v1/images/generations`

**è¯·æ±‚å‚æ•°**:

| å‚æ•° | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `prompt` | string | æ˜¯ | - | å›¾ç‰‡æè¿° |
| `model` | string | å¦ | `gemini-2.5-flash` | å›¾ç‰‡æ¨¡å‹ |
| `n` | int | å¦ | 1 | ç”Ÿæˆæ•°é‡ |
| `response_format` | string | å¦ | `b64_json` | è¿”å›æ ¼å¼ |

**è¯·æ±‚ç¤ºä¾‹**:
```bash
curl -X POST http://82.29.54.80:8100/v1/images/generations \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "ä¸€åªå¯çˆ±çš„æ©˜çŒ«åœ¨é˜³å…‰ä¸‹ç¡è§‰",
    "model": "gemini-3-pro-image-preview",
    "n": 1
  }'
```

**å“åº”æ ¼å¼**:
```json
{
  "created": 1734567890,
  "data": [
    {
      "b64_json": "iVBORw0KGgoAAAANSUhEUgAA..."
    }
  ]
}
```

**Python ç¤ºä¾‹**:
```python
import requests
import base64

response = requests.post(
    "http://82.29.54.80:8100/v1/images/generations",
    json={
        "prompt": "ä¸€åªå¯çˆ±çš„æ©˜çŒ«åœ¨é˜³å…‰ä¸‹ç¡è§‰",
        "model": "gemini-3-pro-image-preview"
    }
)

result = response.json()
image_data = base64.b64decode(result["data"][0]["b64_json"])

# ä¿å­˜å›¾ç‰‡
with open("cat.png", "wb") as f:
    f.write(image_data)
```

---

### æ ¼å¼ 2: Gemini åŸç”Ÿæ ¼å¼ï¼ˆå›¾ç‰‡ç”Ÿæˆï¼‰

**ç«¯ç‚¹**: `POST /gemini/v1beta/models/{model}:generateContent`

å›¾ç‰‡ç”Ÿæˆä½¿ç”¨ä¸æ–‡æœ¬ç›¸åŒçš„æ¥å£ï¼Œæ¨¡å‹ä¼šæ ¹æ®æç¤ºè¯è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡ã€‚

**è¯·æ±‚ç¤ºä¾‹**:
```bash
curl -X POST http://82.29.54.80:8100/gemini/v1beta/models/gemini-3-pro-image-preview:generateContent \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [
      {
        "role": "user",
        "parts": [{"text": "Create an image: ä¸€åªå¯çˆ±çš„æ©˜çŒ«åœ¨é˜³å…‰ä¸‹ç¡è§‰"}]
      }
    ]
  }'
```

**å“åº”æ ¼å¼**:
```json
{
  "candidates": [
    {
      "content": {
        "parts": [
          {"text": "Here is the image..."},
          {
            "inlineData": {
              "mimeType": "image/png",
              "data": "iVBORw0KGgoAAAANSUhEUgAA..."
            }
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP"
    }
  ]
}
```

---

## ğŸ¤ è¯­éŸ³ç”Ÿæˆæ¥å£ï¼ˆTTS - Text-to-Speechï¼‰

> **é‡è¦æç¤º**: è¯­éŸ³åŠŸèƒ½éœ€è¦ä½¿ç”¨ Google AI å®˜æ–¹ API Keyï¼ˆé Cookie æ–¹å¼ï¼‰

### Python SDK è°ƒç”¨ï¼ˆæ¨èï¼‰

**å®‰è£…ä¾èµ–**:
```bash
pip install google-genai
```

**åŸºç¡€ç¤ºä¾‹**:
```python
from google import genai

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = genai.Client(api_key='YOUR_API_KEY')

# æ–‡æœ¬è½¬è¯­éŸ³
response = client.models.generate_content(
    model='gemini-2.5-flash-preview-tts',
    contents='Hello, this is a text-to-speech test. ä½ å¥½ï¼Œè¿™æ˜¯è¯­éŸ³ç”Ÿæˆæµ‹è¯•ã€‚',
    config={'response_modalities': ['AUDIO']}
)

# æå–å¹¶ä¿å­˜éŸ³é¢‘
audio_data = response.candidates[0].content.parts[0].inline_data.data
with open('output.wav', 'wb') as f:
    f.write(audio_data)
```

**å®Œæ•´ç¤ºä¾‹ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰**:
```python
from google import genai

def text_to_speech(api_key: str, text: str, output_file: str):
    """
    Gemini TTS è¯­éŸ³ç”Ÿæˆ

    Args:
        api_key: Google AI API Key
        text: è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬ï¼ˆå»ºè®®3000-5000å­—ç¬¦ä»¥å†…ï¼‰
        output_file: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    """
    client = genai.Client(api_key=api_key)

    try:
        response = client.models.generate_content(
            model='gemini-2.5-flash-preview-tts',
            contents=text,
            config={'response_modalities': ['AUDIO']}
        )

        # æå–éŸ³é¢‘æ•°æ®
        audio_data = response.candidates[0].content.parts[0].inline_data.data
        mime_type = response.candidates[0].content.parts[0].inline_data.mime_type

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        with open(output_file, 'wb') as f:
            f.write(audio_data)

        # è®¡ç®—æ—¶é•¿ï¼ˆPCM 24kHz, 16bit, monoï¼‰
        sample_rate = 24000
        bytes_per_sample = 2
        duration = len(audio_data) / (sample_rate * bytes_per_sample)

        print(f"âœ… éŸ³é¢‘å·²ä¿å­˜: {output_file}")
        print(f"ğŸ“Š å¤§å°: {len(audio_data):,} bytes ({len(audio_data)/1024:.1f} KB)")
        print(f"â±ï¸  æ—¶é•¿: {duration:.2f} ç§’ ({duration/60:.2f} åˆ†é’Ÿ)")
        print(f"ğŸ¼ æ ¼å¼: {mime_type}")

        return duration

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        raise

# ä½¿ç”¨ç¤ºä¾‹
text_to_speech(
    api_key='YOUR_API_KEY',
    text='ä½ å¥½ï¼Œä¸–ç•Œï¼è¿™æ˜¯ä¸€ä¸ªè¯­éŸ³ç”Ÿæˆæµ‹è¯•ã€‚',
    output_file='output.wav'
)
```

**åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬**:
```python
def split_text_for_tts(text: str, max_chars: int = 3000):
    """
    å°†é•¿æ–‡æœ¬åˆ†æ®µï¼Œé¿å…è¶…å‡ºæ—¶é•¿é™åˆ¶

    Args:
        text: åŸå§‹æ–‡æœ¬
        max_chars: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°ï¼ˆæ¨è3000ï¼‰

    Returns:
        åˆ†æ®µåçš„æ–‡æœ¬åˆ—è¡¨
    """
    sentences = text.split('.')
    chunks = []
    current = ''

    for sentence in sentences:
        if len(current) + len(sentence) < max_chars:
            current += sentence + '.'
        else:
            if current:
                chunks.append(current)
            current = sentence + '.'

    if current:
        chunks.append(current)

    return chunks

# ä½¿ç”¨ç¤ºä¾‹
long_text = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬..." * 1000
chunks = split_text_for_tts(long_text, max_chars=3000)

for i, chunk in enumerate(chunks):
    text_to_speech(
        api_key='YOUR_API_KEY',
        text=chunk,
        output_file=f'output_part_{i+1}.wav'
    )
```

### é…é¢ä¸é™åˆ¶

| é¡¹ç›® | å…è´¹å¥—é¤ | ä»˜è´¹å¥—é¤ |
|------|---------|---------|
| **æ¯æ—¥è¯·æ±‚æ•°** | 50æ¬¡ | æ— é™åˆ¶ï¼ˆæŒ‰ç”¨é‡è®¡è´¹ï¼‰ |
| **å•æ¬¡æ—¶é•¿** | 5åˆ†é’Ÿï¼ˆæ¨èï¼‰ | æœ€å¤§11åˆ†é’Ÿ |
| **æ¯æ—¥æ€»æ—¶é•¿** | ~250åˆ†é’Ÿï¼ˆ4.2å°æ—¶ï¼‰ | æ— é™åˆ¶ |
| **éŸ³é¢‘æ ¼å¼** | PCM 24kHz 16bit | åŒå·¦ |
| **è¯­é€Ÿ** | 15-20å­—ç¬¦/ç§’ | åŒå·¦ |

### æœ€ä½³å®è·µ

1. **æ§åˆ¶æ–‡æœ¬é•¿åº¦**: å•æ¬¡è¯·æ±‚æ§åˆ¶åœ¨ 3000-5000 å­—ç¬¦ä»¥å†…ï¼ˆçº¦3-5åˆ†é’ŸéŸ³é¢‘ï¼‰
2. **é•¿æ–‡æœ¬åˆ†æ®µ**: è¶…è¿‡5000å­—ç¬¦å»ºè®®åˆ†æ®µå¤„ç†
3. **é”™è¯¯å¤„ç†**: æ·»åŠ é‡è¯•æœºåˆ¶ï¼Œå¤„ç†ç½‘ç»œè¶…æ—¶
4. **éŸ³é¢‘æ ¼å¼**: è¾“å‡ºä¸º PCM æ ¼å¼ï¼Œå¯ä½¿ç”¨ ffmpeg è½¬æ¢ä¸º MP3ï¼š
   ```bash
   ffmpeg -f s16le -ar 24000 -ac 1 -i input.wav output.mp3
   ```

---

## ğŸ¯ æ”¯æŒçš„æ¨¡å‹

### æ–‡æœ¬æ¨¡å‹

| æ¨¡å‹åç§° | è¯´æ˜ | æ¨èåœºæ™¯ | é€Ÿåº¦ | è´¨é‡ |
|---------|------|---------|------|------|
| **gemini-3-flash-preview** | 3.0 Flash é¢„è§ˆç‰ˆ â­ æ¨è | æœ€æ–°å¿«é€Ÿæ¨¡å‹ | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­â­ |
| **gemini-2.5-flash** | å¿«é€Ÿæ¨¡å‹ | æ—¥å¸¸å¯¹è¯ã€å¿«é€Ÿç”Ÿæˆ | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­ |
| **gemini-2.5-pro** | Proæ¨¡å‹ | é«˜é˜¶æ•°å­¦ã€ä»£ç é—®é¢˜ | âš¡âš¡âš¡âš¡ | â­â­â­â­â­ |
| **gemini-3.0-pro** | 3.0 Pro | æ·±åº¦æ¨ç†ã€å¤æ‚ä»»åŠ¡ | âš¡âš¡âš¡ | â­â­â­â­â­ |
| **gemini-3-pro-preview** | Proé¢„è§ˆç‰ˆï¼ˆåˆ«åï¼‰ | åŒä¸Š | âš¡âš¡âš¡ | â­â­â­â­â­ |

### å›¾ç‰‡æ¨¡å‹

| æ¨¡å‹åç§° | è¯´æ˜ | æ¨èåœºæ™¯ | é€Ÿåº¦ | è´¨é‡ |
|---------|------|---------|------|------|
| **gemini-2.5-flash-image** | å¿«é€Ÿå›¾ç‰‡ç”Ÿæˆ | æ—¥å¸¸å›¾ç‰‡ç”Ÿæˆ | âš¡âš¡âš¡âš¡ | â­â­â­â­ |
| **gemini-3-pro-image-preview** | Proå›¾ç‰‡ç”Ÿæˆ | é«˜è´¨é‡å›¾ç‰‡ | âš¡âš¡ | â­â­â­â­â­ |

### è¯­éŸ³æ¨¡å‹ï¼ˆTTS - Text-to-Speechï¼‰

> **æ³¨æ„**: è¯­éŸ³åŠŸèƒ½éœ€è¦ä½¿ç”¨ Google AI å®˜æ–¹ API Keyï¼Œä¸æ”¯æŒ Cookie æ–¹å¼

| æ¨¡å‹åç§° | è¯´æ˜ | éŸ³é¢‘æ ¼å¼ | å•æ¬¡æ—¶é•¿é™åˆ¶ | é…é¢ |
|---------|------|---------|------------|------|
| **gemini-2.5-flash-preview-tts** | Flash TTSï¼ˆæ¨èï¼‰â­ | PCM 24kHz | 5-7åˆ†é’Ÿ | å…è´¹50æ¬¡/å¤© |
| **gemini-2.5-pro-preview-tts** | Pro TTS | PCM 24kHz | 5-7åˆ†é’Ÿ | å…è´¹50æ¬¡/å¤© |

**TTS æ—¶é•¿é™åˆ¶è¯¦è§£**:

| æ—¶é•¿èŒƒå›´ | ç¨³å®šæ€§ | å»ºè®® | å­—ç¬¦æ•°å‚è€ƒ |
|---------|--------|------|-----------|
| **0-5åˆ†é’Ÿ** | âœ… éå¸¸ç¨³å®š | **æ¨èä½¿ç”¨** | ~3,000-5,000 å­—ç¬¦ |
| **5-7åˆ†é’Ÿ** | âš ï¸ å¯èƒ½æˆªæ–­ | è°¨æ…ä½¿ç”¨ | ~5,000-8,000 å­—ç¬¦ |
| **7-11åˆ†é’Ÿ** | âŒ ç»å¸¸æˆªæ–­ | ä¸æ¨è | > 8,000 å­—ç¬¦ |
| **>11åˆ†é’Ÿ** | âŒ ä¸æ”¯æŒ | å¿…é¡»åˆ†æ®µ | - |

**è¯­é€Ÿå‚è€ƒ**: ä¸­è‹±æ–‡æ··åˆçº¦ 15-20 å­—ç¬¦/ç§’

**å…è´¹é…é¢ä½¿ç”¨æ—¶é•¿**:
- 50æ¬¡ Ã— 5åˆ†é’Ÿ = **250åˆ†é’Ÿï¼ˆ4.2å°æ—¶ï¼‰/å¤©**
- 50æ¬¡ Ã— 3åˆ†é’Ÿ = **150åˆ†é’Ÿï¼ˆ2.5å°æ—¶ï¼‰/å¤©**

**ä»˜è´¹ä»·æ ¼å‚è€ƒ**ï¼ˆä»…ä¾›å‚è€ƒï¼‰:
- æ¯ç§’éŸ³é¢‘ = 25 tokens
- 1å°æ—¶éŸ³é¢‘ â‰ˆ $0.135ï¼ˆçº¦1å…ƒäººæ°‘å¸ï¼‰

**æ¨¡å‹é€‰æ‹©å»ºè®®**:
- æ—¥å¸¸å¯¹è¯ï¼šä½¿ç”¨ `gemini-3-flash-preview`ï¼ˆæœ€æ–°ã€é€Ÿåº¦å¿«ã€è´¨é‡é«˜ï¼‰â­ æ¨è
- å¿«é€Ÿç”Ÿæˆï¼šä½¿ç”¨ `gemini-2.5-flash`ï¼ˆç¨³å®šã€ä¸é™é…é¢ï¼‰
- å¤æ‚æ¨ç†ï¼šä½¿ç”¨ `gemini-2.5-pro` æˆ– `gemini-3.0-pro`
- å›¾ç‰‡ç”Ÿæˆï¼šä½¿ç”¨ `gemini-3-pro-image-preview`ï¼ˆè´¨é‡é«˜ï¼‰
- è¯­éŸ³ç”Ÿæˆï¼šä½¿ç”¨ `gemini-2.5-flash-preview-tts`ï¼ˆç¨³å®šã€å…è´¹50æ¬¡/å¤©ï¼‰â­ æ¨è

---

## ğŸ“Š æ ¼å¼å¯¹æ¯”

| ç‰¹æ€§ | OpenAI æ ¼å¼ | Gemini æ ¼å¼ | ç®€åŒ–æ ¼å¼ |
|------|------------|------------|---------|
| **å…¼å®¹æ€§** | OpenAI å·¥å…·ç›´æ¥ç”¨ | Google å®˜æ–¹æ ¼å¼ | æœ€ç®€å• |
| **Token ç»Ÿè®¡** | âŒ | âœ… | âŒ |
| **å¤šè½®å¯¹è¯** | âœ… æ”¯æŒ | âœ… æ”¯æŒ | âŒ |
| **é…ç½®å‚æ•°** | âŒ | âœ… å®Œæ•´ | âŒ |
| **æ¨èåœºæ™¯** | æ›¿æ¢ OpenAI API | éœ€è¦å®Œæ•´å…ƒæ•°æ® | å¿«é€Ÿæµ‹è¯• |

---

## ğŸ”§ é›†æˆç¤ºä¾‹

### æ›¿æ¢ OpenAI SDK

```python
# åŸæ¥çš„ OpenAI ä»£ç 
# from openai import OpenAI
# client = OpenAI(api_key="sk-xxx")

# æ”¹ä¸ºç›´æ¥ HTTP è°ƒç”¨
import requests

def chat(messages):
    response = requests.post(
        "http://82.29.54.80:8100/v1/chat/completions",
        json={
            "model": "gemini-2.5-flash",
            "messages": messages
        }
    )
    return response.json()["choices"][0]["message"]["content"]

# ä½¿ç”¨æ–¹å¼å®Œå…¨ç›¸åŒ
result = chat([
    {"role": "user", "content": "ä½ å¥½"}
])
print(result)
```

---

### é›†æˆåˆ° LangChain

```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

# ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹
llm = ChatOpenAI(
    model_name="gemini-2.5-flash",
    openai_api_base="http://82.29.54.80:8100/v1",
    openai_api_key="dummy"  # ä¸éœ€è¦çœŸå® key
)

# æ­£å¸¸ä½¿ç”¨
response = llm([HumanMessage(content="ä½ å¥½")])
print(response.content)
```

---

## âš ï¸ é™åˆ¶ä¸é…é¢

### æœåŠ¡é™åˆ¶

| é™åˆ¶é¡¹ | è¯´æ˜ |
|--------|------|
| **ä¾èµ–é…é¢** | ä½¿ç”¨ Google è´¦å·çš„ Gemini åº”ç”¨é…é¢ |
| **Cookie æœ‰æ•ˆæœŸ** | çº¦ 1-2 å‘¨ï¼Œè¿‡æœŸéœ€æ›´æ–° |
| **æµå¼è¾“å‡º** | âŒ æš‚ä¸æ”¯æŒï¼ˆå¼€å‘ä¸­ï¼‰ |
| **å¹¶å‘é™åˆ¶** | å— Google å®˜æ–¹é™åˆ¶ |
| **ä¸Šä¸‹æ–‡çª—å£** | å–å†³äºè´¦å·è®¢é˜…çº§åˆ« |

### Google AI æ–¹æ¡ˆé…é¢

| æ–¹æ¡ˆ | Flash æ¨¡å‹ | Pro æ¨¡å‹ | ä¸Šä¸‹æ–‡çª—å£ |
|------|-----------|----------|-----------|
| **å…è´¹ç‰ˆ** | å¸¸è§„ä½¿ç”¨ | é™é¢ä¸ç¨³å®š | 3.2 ä¸‡ token |
| **Google AI Pro** | å¸¸è§„ä½¿ç”¨ | 100 æ¡/å¤© | 100 ä¸‡ token |
| **Google AI Ultra** | å¸¸è§„ä½¿ç”¨ | 500 æ¡/å¤© | 100 ä¸‡ token |

**å»ºè®®**:
- æ—¥å¸¸ä½¿ç”¨ï¼š`gemini-2.5-flash`ï¼ˆä¸å—é™ï¼‰
- å¤æ‚ä»»åŠ¡ï¼š`gemini-3-pro-preview`ï¼ˆæ³¨æ„é…é¢ï¼‰

---

## âŒ é”™è¯¯å¤„ç†

### æ ‡å‡†é”™è¯¯æ ¼å¼

```json
{
  "detail": "é”™è¯¯æè¿°ä¿¡æ¯"
}
```

### å¸¸è§é”™è¯¯

| HTTP çŠ¶æ€ç  | é”™è¯¯åŸå›  | è§£å†³æ–¹æ³• |
|------------|---------|---------|
| **400** | è¯·æ±‚å‚æ•°é”™è¯¯ | æ£€æŸ¥ `messages` æˆ– `contents` æ˜¯å¦ä¸ºç©º |
| **500** | æœåŠ¡å†…éƒ¨é”™è¯¯ | æ£€æŸ¥æœåŠ¡çŠ¶æ€æˆ–è”ç³»ç®¡ç†å‘˜ |
| **503** | æœåŠ¡ä¸å¯ç”¨ | Cookie å¯èƒ½å·²è¿‡æœŸï¼Œéœ€è¦æ›´æ–° |

### é”™è¯¯å¤„ç†ç¤ºä¾‹

```python
import requests

try:
    response = requests.post(
        "http://82.29.54.80:8100/v1/chat/completions",
        json={
            "model": "gemini-2.5-flash",
            "messages": [{"role": "user", "content": "ä½ å¥½"}]
        }
    )
    response.raise_for_status()
    result = response.json()
    print(result["choices"][0]["message"]["content"])

except requests.exceptions.HTTPError as e:
    print(f"HTTP é”™è¯¯: {e}")
    print(f"è¯¦æƒ…: {e.response.json()}")
except Exception as e:
    print(f"å…¶ä»–é”™è¯¯: {e}")
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ¨¡å‹é€‰æ‹©ç­–ç•¥

```
æ¨èå·¥ä½œæµï¼š
1. é»˜è®¤ä½¿ç”¨ Flashï¼ˆå¿«é€Ÿã€ä¸é™é…é¢ï¼‰
2. éœ€è¦æ·±åº¦æ¨ç†æ—¶åˆ‡æ¢ Pro
3. æ‰¹é‡ä»»åŠ¡ä¼˜å…ˆç”¨ Flash
```

### 2. å¹¶å‘æ§åˆ¶

```python
import asyncio
import aiohttp

async def chat_async(session, message):
    async with session.post(
        "http://82.29.54.80:8100/v1/chat/completions",
        json={
            "model": "gemini-2.5-flash",
            "messages": [{"role": "user", "content": message}]
        }
    ) as response:
        return await response.json()

async def main():
    async with aiohttp.ClientSession() as session:
        tasks = [
            chat_async(session, f"é—®é¢˜ {i}")
            for i in range(10)
        ]
        results = await asyncio.gather(*tasks)
        return results

# è¿è¡Œ
results = asyncio.run(main())
```

### 3. ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def chat_cached(prompt):
    response = requests.post(
        "http://82.29.54.80:8100/v1/chat/completions",
        json={
            "model": "gemini-2.5-flash",
            "messages": [{"role": "user", "content": prompt}]
        }
    )
    return response.json()["choices"][0]["message"]["content"]

# ç›¸åŒé—®é¢˜ä¼šç›´æ¥è¿”å›ç¼“å­˜
result1 = chat_cached("ä»€ä¹ˆæ˜¯AIï¼Ÿ")
result2 = chat_cached("ä»€ä¹ˆæ˜¯AIï¼Ÿ")  # ä½¿ç”¨ç¼“å­˜ï¼Œä¸è°ƒç”¨ API
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

- **æœåŠ¡å™¨**: ç¾å›½æœåŠ¡å™¨ (82.29.54.80)
- **ç«¯å£**: 8000
- **çŠ¶æ€**: âœ… è¿è¡Œä¸­
- **ç»´æŠ¤è€…**: Mason
- **éƒ¨ç½²æ—¶é—´**: 2025-12-17

---

## ğŸ“‹ æ›´æ–°æ—¥å¿—

### v1.1 (2025-12-18)
- âœ… æ·»åŠ  OpenAI å›¾ç‰‡ç”Ÿæˆæ¥å£ `/v1/images/generations`
- âœ… æ·»åŠ å›¾ç‰‡æ¨¡å‹ `gemini-2.5-flash-image` å’Œ `gemini-3-pro-image-preview`
- âœ… æ”¯æŒå¤šè½®å¯¹è¯å†å²
- âœ… é…ç½®åŸŸå `google-api.aihang365.com`
- âœ… ç«¯å£æ”¹ä¸º 8100

### v1.0 (2025-12-17)
- âœ… æ”¯æŒ OpenAI å…¼å®¹æ ¼å¼
- âœ… æ”¯æŒ Gemini åŸç”Ÿæ ¼å¼
- âœ… æ”¯æŒç®€åŒ–æ ¼å¼
- âœ… æ”¯æŒå¤šç§æ¨¡å‹åˆ‡æ¢
- âœ… å®Œæ•´é”™è¯¯å¤„ç†

---

## ğŸ”— ç›¸å…³é“¾æ¥

- **æœåŠ¡ç«¯ç‚¹**: http://82.29.54.80:8100
- **åŸŸåè®¿é—®**: http://google-api.aihang365.com:8100
- **å¥åº·æ£€æŸ¥**: http://82.29.54.80:8100/health
- **Webé…ç½®ç•Œé¢**: http://82.29.54.80:8100
- **API æ–‡æ¡£**: http://82.29.54.80:8100/docs (FastAPI è‡ªåŠ¨ç”Ÿæˆ)

---

## ğŸ”Œ new-api æ¥å…¥é…ç½®

åœ¨ new-api ä¸­æ·»åŠ è‡ªå®šä¹‰æ¸ é“ï¼š

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| ç±»å‹ | OpenAI |
| åç§° | Gemini-Reverse |
| Base URL | `http://82.29.54.80:8100` |
| å¯†é’¥ | ä»»æ„å€¼ï¼ˆå¦‚ `sk-gemini-local`ï¼‰ |
| æ–‡æœ¬æ¨¡å‹ | `gemini-2.5-flash,gemini-2.5-pro,gemini-3.0-pro,gemini-3-pro-preview` |
| å›¾ç‰‡æ¨¡å‹ | `gemini-2.5-flash-image,gemini-3-pro-image-preview` |

---

**æœ€åæ›´æ–°**: 2025-12-18
